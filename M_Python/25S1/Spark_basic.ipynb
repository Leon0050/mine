{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fea1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790e4c9",
   "metadata": {},
   "source": [
    "#### Words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc21a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022c9701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "data = [1,2,3,4,5]\n",
    "distData = sc.parallelize(data,8)\n",
    "s = distData.reduce(lambda a,b : a*b)  # reduce表示进行聚合操作\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4846d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['line1', 'This is line2']\n"
     ]
    }
   ],
   "source": [
    "file = [\"line1\", \"This is line2\"]\n",
    "lines = sc.parallelize(file)\n",
    "print(lines.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886b415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['line1', 'This is line2']\n"
     ]
    }
   ],
   "source": [
    "print(lines.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40df9440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 13]\n"
     ]
    }
   ],
   "source": [
    "linelengthes = lines.map(lambda line:len(line))\n",
    "print(linelengthes.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d032ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceFunc(a,b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1473fb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "totalLength = linelengthes.reduce(reduceFunc)\n",
    "print(totalLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e875ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[6] at collect at /tmp/ipykernel_41/1028932533.py:2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linelengthes.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9ef8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello this is line one', 'hello this is line two']\n"
     ]
    }
   ],
   "source": [
    "words = ['hello this is line one', 'hello this is line two']\n",
    "words_rdd = sc.parallelize(words)\n",
    "print(words_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf8ee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'this', 'is', 'line', 'one', 'hello', 'this', 'is', 'line', 'two']\n"
     ]
    }
   ],
   "source": [
    "words_rdd = words_rdd.flatMap(lambda line: line.split(\" \"))\n",
    "print(words_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa701aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 1), ('this', 1), ('is', 1), ('line', 1), ('one', 1), ('hello', 1), ('this', 1), ('is', 1), ('line', 1), ('two', 1)]\n"
     ]
    }
   ],
   "source": [
    "paris = words_rdd.map(lambda s:(s,1))\n",
    "print(paris.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "625f6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('two', 1), ('hello', 2), ('this', 2), ('line', 2), ('is', 2), ('one', 1)]\n"
     ]
    }
   ],
   "source": [
    "counts = paris.reduceByKey(lambda a,b:a + b)  #对键进行聚合操作\n",
    "print(counts.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8481b",
   "metadata": {},
   "source": [
    "#### Pi estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b60ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def inside(p):\n",
    "    x,y = random.random(), random.random()\n",
    "    return x*x + y*y <1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b20bf8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.141820\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 1000000\n",
    "count = sc.parallelize(range(0, NUM_SAMPLES))\\\n",
    "        .filter(inside).count()\n",
    "print(\"Pi is roughly %f\" % (4.0 *count / NUM_SAMPLES))  # pi*r^2 / (2r)^2 = pi/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee1db2",
   "metadata": {},
   "source": [
    "#### DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71fbbab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "| name|Sex|age|\n",
      "+-----+---+---+\n",
      "|  TOM|  M| 30|\n",
      "|  SAY|  F| 24|\n",
      "|Marry|  M| 43|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"DataFrame Example\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (\"TOM\", \"M\", 30), \n",
    "    (\"SAY\", \"F\", 24), \n",
    "    (\"Marry\", \"M\", 43)\n",
    "], [\"name\", \"Sex\", \"age\"])\n",
    "\n",
    "# df = sc.parallelize([(\"TOM\", \"M\", 30), (\"SAY\", \"F\", 24), (\"Marry\", \"M\", 43)])\\\n",
    "#     .toDF([\"name\", \"Sex\", \"age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8847fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 30|    1|\n",
      "| 24|    1|\n",
      "| 43|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countByCol = df.groupBy(\"age\").count()\n",
    "countByCol.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9babbd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Sex|\n",
      "+---+\n",
      "|  M|\n",
      "|  F|\n",
      "|  M|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Sex\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71aa927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "| name|Sex|age|\n",
      "+-----+---+---+\n",
      "|  TOM|  M| 30|\n",
      "|Marry|  M| 43|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "errors = df.filter(col('age') >25)\n",
    "errors.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
